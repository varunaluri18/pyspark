{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark_structured.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPvcR2S/Cuio4bpzOFmH/kH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varunaluri18/pyspark/blob/main/pyspark_structured.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHIJ-Jm9KfGn",
        "outputId": "2d920aab-bbd2-438e-fc64-8dfd18a6d825"
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 40 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 41.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=c59f25c0488784296ef4cee4aff6d6f3c405aa69ad6e6b12b96a2d3efaa5eb88\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "i-MrJc2TKq2o",
        "outputId": "bec6c011-d417-4eb6-a4a1-4465e153bea7"
      },
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark =SparkSession.builder.appName('firstprogram').getOrCreate()\n",
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://3e2391c6c78f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>firstprogram</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f76c9d48cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YFOTw5yHpMx",
        "outputId": "b9953895-97fa-443e-8a34-ec6310a33c81"
      },
      "source": [
        "data=[('varun','nagendra','M',28000),('sravani','yakkanti','F',27000),('sri','vidya','NA',26000),('ishwarya','himabindu','F',26500),(None,'kaveri','F',24900)]\n",
        "columns=[\"firstname\",\"lastname\",\"gender\",\"salary\"]\n",
        "df=spark.createDataFrame(data=data, schema = columns)\n",
        "df.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+\n",
            "|firstname|lastname |gender|salary|\n",
            "+---------+---------+------+------+\n",
            "|varun    |nagendra |M     |28000 |\n",
            "|sravani  |yakkanti |F     |27000 |\n",
            "|sri      |vidya    |NA    |26000 |\n",
            "|ishwarya |himabindu|F     |26500 |\n",
            "|null     |kaveri   |F     |24900 |\n",
            "+---------+---------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5wqVvstVS0N",
        "outputId": "918e10a2-4791-4837-ce8e-8c5588d78091"
      },
      "source": [
        "print(df.collect())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Row(firstname='varun', lastname='nagendra', gender='M', salary=28000), Row(firstname='sravani', lastname='yakkanti', gender='F', salary=27000), Row(firstname='sri', lastname='vidya', gender='NA', salary=26000), Row(firstname='ishwarya', lastname='himabindu', gender='F', salary=26500), Row(firstname=None, lastname='kaveri', gender='F', salary=24900)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPBRjLTWHz-X",
        "outputId": "9f266d5d-afd9-4021-b444-48cf7bd5630c"
      },
      "source": [
        "df2=df.withColumn(\"salary\", df.salary*3)\n",
        "df2.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+\n",
            "|firstname| lastname|gender|salary|\n",
            "+---------+---------+------+------+\n",
            "|    varun| nagendra|     M| 84000|\n",
            "|  sravani| yakkanti|     F| 81000|\n",
            "|      sri|    vidya|    NA| 78000|\n",
            "| ishwarya|himabindu|     F| 79500|\n",
            "|     null|   kaveri|     F| 74700|\n",
            "+---------+---------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN4j4CcQIdhH",
        "outputId": "cf464ca1-9f45-400b-8209-acf2cee2e351"
      },
      "source": [
        "from pyspark.sql.functions import when\n",
        "df3 = df.withColumn(\"gender\", when(df.gender == \"M\",\"Male\").when(df.gender == \"F\",\"Female\").otherwise(df.gender))\n",
        "df3.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+\n",
            "|firstname| lastname|gender|salary|\n",
            "+---------+---------+------+------+\n",
            "|    varun| nagendra|  Male| 28000|\n",
            "|  sravani| yakkanti|Female| 27000|\n",
            "|      sri|    vidya|    NA| 26000|\n",
            "| ishwarya|himabindu|Female| 26500|\n",
            "|     null|   kaveri|Female| 24900|\n",
            "+---------+---------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol5w14ydIoVk",
        "outputId": "77e7fa99-2a15-4bf5-be92-20313701fbc2"
      },
      "source": [
        "df4=df.withColumn(\"salary\",df.salary.cast(\"String\"))\n",
        "df4.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbmTcDwuJPE2",
        "outputId": "d5075a79-40e0-45c1-b1f2-a6511508012e"
      },
      "source": [
        "df.createOrReplaceTempView(\"PER\")\n",
        "df5=spark.sql(\"select firstname,gender,salary*3 as salary from PER\")\n",
        "df5.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------+------+\n",
            "|firstname|gender|salary|\n",
            "+---------+------+------+\n",
            "|    varun|     M| 84000|\n",
            "|  sravani|     F| 81000|\n",
            "|      sri|    NA| 78000|\n",
            "| ishwarya|     F| 79500|\n",
            "|     null|     F| 74700|\n",
            "+---------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l68L2BuIXKPQ"
      },
      "source": [
        "# Pandas-PySpark-DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfMlh4AoVd6a",
        "outputId": "b6858247-28e1-4942-a25d-ef33d3098f4b"
      },
      "source": [
        "import pandas as pd    \n",
        "data = [['varun', 24], ['sravani', 23], ['ishwarya', 27],['vidya', 25]]   \n",
        "pandasDF = pd.DataFrame(data, columns = ['Name', 'Age']) \n",
        "print(pandasDF,type(pandasDF))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Name  Age\n",
            "0     varun   24\n",
            "1   sravani   23\n",
            "2  ishwarya   27\n",
            "3     vidya   25 <class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ_uINlKWIKb",
        "outputId": "04ad5b74-f0aa-4685-e536-52dd9a41c39c"
      },
      "source": [
        "sparkDF=spark.createDataFrame(pandasDF) \n",
        "sparkDF.printSchema()\n",
        "sparkDF.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Age: long (nullable = true)\n",
            "\n",
            "+--------+---+\n",
            "|    Name|Age|\n",
            "+--------+---+\n",
            "|   varun| 24|\n",
            "| sravani| 23|\n",
            "|ishwarya| 27|\n",
            "|   vidya| 25|\n",
            "+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUXxJ84MWMlL"
      },
      "source": [
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
        "mySchema = StructType([ StructField(\"First Name\", StringType(), True),StructField(\"Age\", IntegerType(), True)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzKUtEKUWcVO",
        "outputId": "2e17c344-f704-42e0-ee54-06fc5368a638"
      },
      "source": [
        "sparkDF2 = spark.createDataFrame(pandasDF,schema=mySchema)\n",
        "sparkDF2.printSchema()\n",
        "sparkDF2.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- First Name: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            "\n",
            "+----------+---+\n",
            "|First Name|Age|\n",
            "+----------+---+\n",
            "|     varun| 24|\n",
            "|   sravani| 23|\n",
            "|  ishwarya| 27|\n",
            "|     vidya| 25|\n",
            "+----------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOGTmKEtWizf"
      },
      "source": [
        "spark.conf.set(\"spark.sql.execution.arrow.enabled\",\"true\")\n",
        "spark.conf.set(\"spark.sql.execution.arrow.pyspark.fallback.enabled\",\"true\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mNIiJa2XwtX"
      },
      "source": [
        "# adding months"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc2xDeYVYQmg",
        "outputId": "ec24fe10-e227-4878-ac7d-60b79cfe113e"
      },
      "source": [
        "from pyspark.sql.functions import col,expr\n",
        "data=[(\"2019-01-23\",1),(\"2019-06-24\",2),(\"2019-09-20\",3)]\n",
        "spark.createDataFrame(data).toDF(\"date\",\"increment\").select(col(\"date\"),col(\"increment\"),expr(\"add_months(to_date(date,'yyyy-MM-dd'),cast(increment as int))\").alias(\"inc_date\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+----------+\n",
            "|      date|increment|  inc_date|\n",
            "+----------+---------+----------+\n",
            "|2019-01-23|        1|2019-02-23|\n",
            "|2019-06-24|        2|2019-08-24|\n",
            "|2019-09-20|        3|2019-12-20|\n",
            "+----------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhEwgACDYRul"
      },
      "source": [
        "# adding new coloumn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTIZ829iYUV5",
        "outputId": "f06a58f8-9c79-495a-e8e0-e2aeb69bb9bf"
      },
      "source": [
        "data=[('varun','nagendra','M',28000),('sravani','yakkanti','F',27000),('sri','vidya','NA',26000),('ishwarya','himabindu','F',26500),('kaveri','rayi','F',24900)]\n",
        "columns=[\"firstname\",\"lastname\",\"gender\",\"salary\"]\n",
        "df=spark.createDataFrame(data=data, schema = columns)\n",
        "df.show(truncate=False)\n",
        "if 'age' not in df.columns:\n",
        "    print(\"No age was defined in the data frame\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+------+------+\n",
            "|firstname|lastname |gender|salary|\n",
            "+---------+---------+------+------+\n",
            "|varun    |nagendra |M     |28000 |\n",
            "|sravani  |yakkanti |F     |27000 |\n",
            "|sri      |vidya    |NA    |26000 |\n",
            "|ishwarya |himabindu|F     |26500 |\n",
            "|kaveri   |rayi     |F     |24900 |\n",
            "+---------+---------+------+------+\n",
            "\n",
            "No age was defined in the data frame\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GuDY3I0ZznG",
        "outputId": "cc490a9e-c17b-4e0f-d0e9-cb7b8c935d96"
      },
      "source": [
        "from pyspark.sql.functions import lit\n",
        "print('Adding the new coloumn using lit function')\n",
        "df.withColumn(\"bonus_percent\", lit(0.3)).show()\n",
        "\n",
        "print('Add column from existing column')\n",
        "df.withColumn(\"bonus_amount\", df.salary*0.3).show()\n",
        "\n",
        "print('Add column by concatinating existing column using concat_ws')\n",
        "from pyspark.sql.functions import concat_ws\n",
        "df.withColumn(\"name\", concat_ws(\" \",\"firstname\",'lastname')).show()\n",
        "\n",
        "print(\"Add current date\")\n",
        "from pyspark.sql.functions import current_date\n",
        "df.withColumn(\"current_date\", current_date()).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding the new coloumn using lit function\n",
            "+---------+---------+------+------+-------------+\n",
            "|firstname| lastname|gender|salary|bonus_percent|\n",
            "+---------+---------+------+------+-------------+\n",
            "|    varun| nagendra|     M| 28000|          0.3|\n",
            "|  sravani| yakkanti|     F| 27000|          0.3|\n",
            "|      sri|    vidya|    NA| 26000|          0.3|\n",
            "| ishwarya|himabindu|     F| 26500|          0.3|\n",
            "|   kaveri|     rayi|     F| 24900|          0.3|\n",
            "+---------+---------+------+------+-------------+\n",
            "\n",
            "Add column from existing column\n",
            "+---------+---------+------+------+------------+\n",
            "|firstname| lastname|gender|salary|bonus_amount|\n",
            "+---------+---------+------+------+------------+\n",
            "|    varun| nagendra|     M| 28000|      8400.0|\n",
            "|  sravani| yakkanti|     F| 27000|      8100.0|\n",
            "|      sri|    vidya|    NA| 26000|      7800.0|\n",
            "| ishwarya|himabindu|     F| 26500|      7950.0|\n",
            "|   kaveri|     rayi|     F| 24900|      7470.0|\n",
            "+---------+---------+------+------+------------+\n",
            "\n",
            "Add column by concatinating existing column using concat_ws\n",
            "+---------+---------+------+------+------------------+\n",
            "|firstname| lastname|gender|salary|              name|\n",
            "+---------+---------+------+------+------------------+\n",
            "|    varun| nagendra|     M| 28000|    varun nagendra|\n",
            "|  sravani| yakkanti|     F| 27000|  sravani yakkanti|\n",
            "|      sri|    vidya|    NA| 26000|         sri vidya|\n",
            "| ishwarya|himabindu|     F| 26500|ishwarya himabindu|\n",
            "|   kaveri|     rayi|     F| 24900|       kaveri rayi|\n",
            "+---------+---------+------+------+------------------+\n",
            "\n",
            "Add current date\n",
            "+---------+---------+------+------+------------+\n",
            "|firstname| lastname|gender|salary|current_date|\n",
            "+---------+---------+------+------+------------+\n",
            "|    varun| nagendra|     M| 28000|  2021-11-18|\n",
            "|  sravani| yakkanti|     F| 27000|  2021-11-18|\n",
            "|      sri|    vidya|    NA| 26000|  2021-11-18|\n",
            "| ishwarya|himabindu|     F| 26500|  2021-11-18|\n",
            "|   kaveri|     rayi|     F| 24900|  2021-11-18|\n",
            "+---------+---------+------+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI1cJvq4a9Uc",
        "outputId": "4fbc45bb-7b42-4557-83cf-c3b8da7a21ed"
      },
      "source": [
        "from pyspark.sql.functions import when\n",
        "from pyspark.sql.functions import lit\n",
        "print('Using the lit and when function')\n",
        "df.withColumn(\"grade\",when((df.salary >=27000), lit(\"A\")).when((df.salary <27000) & (df.salary >=25000), lit(\"B\")).otherwise(lit(\"C\"))).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the lit and when function\n",
            "+---------+---------+------+------+-----+\n",
            "|firstname| lastname|gender|salary|grade|\n",
            "+---------+---------+------+------+-----+\n",
            "|    varun| nagendra|     M| 28000|    A|\n",
            "|  sravani| yakkanti|     F| 27000|    A|\n",
            "|      sri|    vidya|    NA| 26000|    B|\n",
            "| ishwarya|himabindu|     F| 26500|    B|\n",
            "|   kaveri|     rayi|     F| 24900|    C|\n",
            "+---------+---------+------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B0OvnY9bPjR",
        "outputId": "4b5b0417-caf7-4a2b-846b-be249a9c603a"
      },
      "source": [
        "print('Adding coloumn using select')\n",
        "from pyspark.sql.functions import lit\n",
        "df.select(\"firstname\",\"salary\", lit(0.3).alias(\"bonus\")).show()\n",
        "df.select(\"firstname\",\"salary\", lit(df.salary * 0.3).alias(\"bonus_amount\")).show()\n",
        "df.select(\"firstname\",\"salary\", current_date().alias(\"today_date\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding coloumn using select\n",
            "+---------+------+-----+\n",
            "|firstname|salary|bonus|\n",
            "+---------+------+-----+\n",
            "|    varun| 28000|  0.3|\n",
            "|  sravani| 27000|  0.3|\n",
            "|      sri| 26000|  0.3|\n",
            "| ishwarya| 26500|  0.3|\n",
            "|   kaveri| 24900|  0.3|\n",
            "+---------+------+-----+\n",
            "\n",
            "+---------+------+------------+\n",
            "|firstname|salary|bonus_amount|\n",
            "+---------+------+------------+\n",
            "|    varun| 28000|      8400.0|\n",
            "|  sravani| 27000|      8100.0|\n",
            "|      sri| 26000|      7800.0|\n",
            "| ishwarya| 26500|      7950.0|\n",
            "|   kaveri| 24900|      7470.0|\n",
            "+---------+------+------------+\n",
            "\n",
            "+---------+------+----------+\n",
            "|firstname|salary|today_date|\n",
            "+---------+------+----------+\n",
            "|    varun| 28000|2021-11-18|\n",
            "|  sravani| 27000|2021-11-18|\n",
            "|      sri| 26000|2021-11-18|\n",
            "| ishwarya| 26500|2021-11-18|\n",
            "|   kaveri| 24900|2021-11-18|\n",
            "+---------+------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWc-ns2nb7ko",
        "outputId": "0b32d200-8e73-4ee7-c61f-19417a670081"
      },
      "source": [
        "print('Ading coloumns using Spark SQL')\n",
        "df.createOrReplaceTempView(\"temp\")\n",
        "spark.sql(\"select firstname,salary, '0.3' as bonus from temp\").show()\n",
        "spark.sql(\"select firstname,salary, salary * 0.3 as bonus_amount from temp\").show()\n",
        "spark.sql(\"select firstname,salary, current_date() as today_date from temp\").show()\n",
        "\n",
        "print('Using CASE statement in SQL')\n",
        "spark.sql(\"select firstname,salary, \" +\"case salary when salary > 25000 then 'B' \"+\"else 'B' END as grade from temp\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ading coloumns using Spark SQL\n",
            "+---------+------+-----+\n",
            "|firstname|salary|bonus|\n",
            "+---------+------+-----+\n",
            "|    varun| 28000|  0.3|\n",
            "|  sravani| 27000|  0.3|\n",
            "|      sri| 26000|  0.3|\n",
            "| ishwarya| 26500|  0.3|\n",
            "|   kaveri| 24900|  0.3|\n",
            "+---------+------+-----+\n",
            "\n",
            "+---------+------+------------+\n",
            "|firstname|salary|bonus_amount|\n",
            "+---------+------+------------+\n",
            "|    varun| 28000|      8400.0|\n",
            "|  sravani| 27000|      8100.0|\n",
            "|      sri| 26000|      7800.0|\n",
            "| ishwarya| 26500|      7950.0|\n",
            "|   kaveri| 24900|      7470.0|\n",
            "+---------+------+------------+\n",
            "\n",
            "+---------+------+----------+\n",
            "|firstname|salary|today_date|\n",
            "+---------+------+----------+\n",
            "|    varun| 28000|2021-11-18|\n",
            "|  sravani| 27000|2021-11-18|\n",
            "|      sri| 26000|2021-11-18|\n",
            "| ishwarya| 26500|2021-11-18|\n",
            "|   kaveri| 24900|2021-11-18|\n",
            "+---------+------+----------+\n",
            "\n",
            "Using CASE statement in SQL\n",
            "+---------+------+-----+\n",
            "|firstname|salary|grade|\n",
            "+---------+------+-----+\n",
            "|    varun| 28000|    B|\n",
            "|  sravani| 27000|    B|\n",
            "|      sri| 26000|    B|\n",
            "| ishwarya| 26500|    B|\n",
            "|   kaveri| 24900|    B|\n",
            "+---------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5xCxxUVb_T5",
        "outputId": "e17ee7e1-ccc2-47d0-9e9f-f87ec0d7fe1d"
      },
      "source": [
        "print(\"Applying Aggrigate Functions\")\n",
        "from pyspark.sql.functions import approx_count_distinct,collect_list\n",
        "from pyspark.sql.functions import collect_set,sum,avg,max,countDistinct,count\n",
        "from pyspark.sql.functions import first, last, kurtosis, min, mean, skewness \n",
        "from pyspark.sql.functions import stddev, stddev_samp, stddev_pop, sumDistinct\n",
        "from pyspark.sql.functions import variance,var_samp,  var_pop"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying Aggrigate Functions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOhu_9-xgYvS",
        "outputId": "c60b900c-7757-4981-a966-d54c88ab597d"
      },
      "source": [
        "print(\"Distinct Salaries: \" +str(df.select(approx_count_distinct(\"salary\")).collect()[0][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distinct Salaries: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3jhHiA-iWWM",
        "outputId": "65e0a995-81cb-443e-e972-d29de8d1710a"
      },
      "source": [
        "df.select(countDistinct(\"firstname\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------+\n",
            "|count(DISTINCT firstname)|\n",
            "+-------------------------+\n",
            "|                        5|\n",
            "+-------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SmMoJZEgxgQ",
        "outputId": "f9f070a6-e801-4471-af7c-6fdcadc80c80"
      },
      "source": [
        "print(\"Average salary of all the employees: \" + str(df.select(avg(\"salary\")).collect()[0][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average salary of all the employees: 26480.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFhsP6nbg5uJ",
        "outputId": "cfe77418-13ed-4ed3-a86f-aa4083e8a268"
      },
      "source": [
        "df.select(collect_list(\"salary\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------+\n",
            "|collect_list(salary)               |\n",
            "+-----------------------------------+\n",
            "|[28000, 27000, 26000, 26500, 24900]|\n",
            "+-----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EXCWn-GhRjl",
        "outputId": "05614b7d-00fd-40d2-c4b6-923d0cb15405"
      },
      "source": [
        "df.select(collect_set(\"salary\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------+\n",
            "|collect_set(salary)                |\n",
            "+-----------------------------------+\n",
            "|[26000, 24900, 26500, 27000, 28000]|\n",
            "+-----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlXQu0wahYUS",
        "outputId": "cb295f38-aef2-401b-cc99-84a97200bf99"
      },
      "source": [
        "simpleData = [(\"James\", \"Sales\", 3000),(\"Michael\", \"Sales\", 4600),(\"Robert\", \"Sales\", 4100),(\"Maria\", \"Finance\", 3000),(\"James\", \"Sales\", 3000),(\"Scott\", \"Finance\", 3300),(\"Jen\", \"Finance\", 3900),(\"Jeff\", \"Marketing\", 3000),(\"Kumar\", \"Marketing\", 2000),(\"Saif\", \"Sales\", 4100)]\n",
        "schema = [\"employee_name\", \"department\", \"salary\"]\n",
        "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- employee_name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|James        |Sales     |3000  |\n",
            "|Michael      |Sales     |4600  |\n",
            "|Robert       |Sales     |4100  |\n",
            "|Maria        |Finance   |3000  |\n",
            "|James        |Sales     |3000  |\n",
            "|Scott        |Finance   |3300  |\n",
            "|Jen          |Finance   |3900  |\n",
            "|Jeff         |Marketing |3000  |\n",
            "|Kumar        |Marketing |2000  |\n",
            "|Saif         |Sales     |4100  |\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxwaEGexhfqq",
        "outputId": "00659e47-0232-41c5-dba7-fba77123bfa0"
      },
      "source": [
        "df2 = df.select(countDistinct(\"department\", \"salary\"))\n",
        "df2.show(truncate=False)\n",
        "print(\"Distinct Count of Department &amp; Salary: \"+str(df2.collect()[0][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------+\n",
            "|count(DISTINCT department, salary)|\n",
            "+----------------------------------+\n",
            "|8                                 |\n",
            "+----------------------------------+\n",
            "\n",
            "Distinct Count of Department &amp; Salary: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxwtCxN3h69R",
        "outputId": "a41e7ffe-e20b-44a0-be52-8891464bb3dd"
      },
      "source": [
        "print(\"count: \"+str(df.select(count(\"department\")).collect()[0][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuHIkQfYkvwY",
        "outputId": "5e0f56d0-251a-451f-c84a-9315e351e632"
      },
      "source": [
        "print('Salary of the first person on the top')\n",
        "df.select(first(\"salary\")).show(truncate=False)\n",
        "\n",
        "print('Salary of the last person on the bottom')\n",
        "df.select(last(\"salary\")).show(truncate=False)\n",
        "\n",
        "print('Finding Kurtosis')\n",
        "df.select(kurtosis(\"salary\")).show(truncate=False)\n",
        "\n",
        "print('Finding Skewness')\n",
        "df.select(skewness(\"salary\")).show(truncate=False)\n",
        "\n",
        "print('Finding Maximum')\n",
        "df.select(max(\"salary\")).show(truncate=False)\n",
        "\n",
        "print('Finding Minimum')\n",
        "df.select(min(\"salary\")).show(truncate=False)\n",
        "\n",
        "print('Finding Average')\n",
        "df.select(mean(\"salary\")).show(truncate=False)\n",
        "\n",
        "print('Finding the sum of distinct salaries')\n",
        "df.select(sumDistinct(\"salary\")).show(truncate=False)\n",
        "\n",
        "print('Finding standard deviation')\n",
        "df.select(stddev(\"salary\"), stddev_samp(\"salary\"),stddev_pop(\"salary\")).show(truncate=False)\n",
        "\n",
        "print('Finding varience')\n",
        "df.select(variance(\"salary\"),var_samp(\"salary\"),var_pop(\"salary\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salary of the first person on the top\n",
            "+-------------+\n",
            "|first(salary)|\n",
            "+-------------+\n",
            "|3000         |\n",
            "+-------------+\n",
            "\n",
            "Salary of the last person on the bottom\n",
            "+------------+\n",
            "|last(salary)|\n",
            "+------------+\n",
            "|4100        |\n",
            "+------------+\n",
            "\n",
            "Finding Kurtosis\n",
            "+-------------------+\n",
            "|kurtosis(salary)   |\n",
            "+-------------------+\n",
            "|-0.6467803030303032|\n",
            "+-------------------+\n",
            "\n",
            "Finding Skewness\n",
            "+--------------------+\n",
            "|skewness(salary)    |\n",
            "+--------------------+\n",
            "|-0.12041791181069571|\n",
            "+--------------------+\n",
            "\n",
            "Finding Maximum\n",
            "+-----------+\n",
            "|max(salary)|\n",
            "+-----------+\n",
            "|4600       |\n",
            "+-----------+\n",
            "\n",
            "Finding Minimum\n",
            "+-----------+\n",
            "|min(salary)|\n",
            "+-----------+\n",
            "|2000       |\n",
            "+-----------+\n",
            "\n",
            "Finding Average\n",
            "+-----------+\n",
            "|avg(salary)|\n",
            "+-----------+\n",
            "|3400.0     |\n",
            "+-----------+\n",
            "\n",
            "Finding the sum of distinct salaries\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/functions.py:214: FutureWarning: Deprecated in 3.2, use sum_distinct instead.\n",
            "  warnings.warn(\"Deprecated in 3.2, use sum_distinct instead.\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|sum(DISTINCT salary)|\n",
            "+--------------------+\n",
            "|20900               |\n",
            "+--------------------+\n",
            "\n",
            "Finding standard deviation\n",
            "+-------------------+-------------------+------------------+\n",
            "|stddev_samp(salary)|stddev_samp(salary)|stddev_pop(salary)|\n",
            "+-------------------+-------------------+------------------+\n",
            "|765.9416862050705  |765.9416862050705  |726.636084983398  |\n",
            "+-------------------+-------------------+------------------+\n",
            "\n",
            "Finding varience\n",
            "+-----------------+-----------------+---------------+\n",
            "|var_samp(salary) |var_samp(salary) |var_pop(salary)|\n",
            "+-----------------+-----------------+---------------+\n",
            "|586666.6666666666|586666.6666666666|528000.0       |\n",
            "+-----------------+-----------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF-5m0XRnTiQ",
        "outputId": "cf622c3a-f34a-4746-ebef-c81f6d4c8a61"
      },
      "source": [
        "print('PySpark Array String')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PySpark Array String\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bocB0eFdleTq",
        "outputId": "e830ffd3-cae5-4d6b-ee81-8c967c544de3"
      },
      "source": [
        "columns = [\"name\",\"languagesAtSchool\",\"currentState\"]\n",
        "data = [(\"James,Smith\",[\"Java\",\"Scala\",\"C++\"],\"CA\"),(\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],\"NJ\"),(\"Robert,Williams\",[\"CSharp\",\"VB\"],\"NV\")]\n",
        "df = spark.createDataFrame(data=data,schema=columns)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- languagesAtSchool: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- currentState: string (nullable = true)\n",
            "\n",
            "+---------------+------------------+------------+\n",
            "|           name| languagesAtSchool|currentState|\n",
            "+---------------+------------------+------------+\n",
            "|    James,Smith|[Java, Scala, C++]|          CA|\n",
            "|  Michael,Rose,|[Spark, Java, C++]|          NJ|\n",
            "|Robert,Williams|      [CSharp, VB]|          NV|\n",
            "+---------------+------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sKA8wfLmnY4",
        "outputId": "a7ff1eca-4e63-442b-e502-46e680dc7bea"
      },
      "source": [
        "from pyspark.sql.functions import col, concat_ws\n",
        "df2 = df.withColumn(\"languagesAtSchool\",concat_ws(\",\",col(\"languagesAtSchool\")))\n",
        "df2.printSchema()\n",
        "df2.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- languagesAtSchool: string (nullable = false)\n",
            " |-- currentState: string (nullable = true)\n",
            "\n",
            "+---------------+-----------------+------------+\n",
            "|name           |languagesAtSchool|currentState|\n",
            "+---------------+-----------------+------------+\n",
            "|James,Smith    |Java,Scala,C++   |CA          |\n",
            "|Michael,Rose,  |Spark,Java,C++   |NJ          |\n",
            "|Robert,Williams|CSharp,VB        |NV          |\n",
            "+---------------+-----------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBNHRhC0m6eD",
        "outputId": "5f792220-c829-4ed6-8595-760a5b6b5ded"
      },
      "source": [
        "df.createOrReplaceTempView(\"arr\")\n",
        "spark.sql(\"select name, concat_ws(',',languagesAtSchool) as languagesAtSchool,\" + \" currentState from arr\").show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----------------+------------+\n",
            "|name           |languagesAtSchool|currentState|\n",
            "+---------------+-----------------+------------+\n",
            "|James,Smith    |Java,Scala,C++   |CA          |\n",
            "|Michael,Rose,  |Spark,Java,C++   |NJ          |\n",
            "|Robert,Williams|CSharp,VB        |NV          |\n",
            "+---------------+-----------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcapC8YZXx2V",
        "outputId": "693ca661-96d4-4927-ac36-50e21d923375"
      },
      "source": [
        "print('changing the data types of the coloumns')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "changing the data types of the coloumns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DguotWrzVGAu",
        "outputId": "458c2c97-268f-4ae4-abb2-e366309d7295"
      },
      "source": [
        "simpleData = [(\"varun\",34,\"2006-01-01\",\"true\",\"M\",3000.60),(\"sravani\",33,\"1980-01-10\",\"true\",\"F\",3300.80),(\"vidya\",37,\"06-01-1992\",\"false\",\"F\",5000.50)]\n",
        "columns = [\"firstname\",\"age\",\"jobStartDate\",\"isGraduated\",\"gender\",\"salary\"]\n",
        "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "changing the data types of the coloumns\n",
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            " |-- jobStartDate: string (nullable = true)\n",
            " |-- isGraduated: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: double (nullable = true)\n",
            "\n",
            "+---------+---+------------+-----------+------+------+\n",
            "|firstname|age|jobStartDate|isGraduated|gender|salary|\n",
            "+---------+---+------------+-----------+------+------+\n",
            "|varun    |34 |2006-01-01  |true       |M     |3000.6|\n",
            "|sravani  |33 |1980-01-10  |true       |F     |3300.8|\n",
            "|vidya    |37 |06-01-1992  |false      |F     |5000.5|\n",
            "+---------+---+------------+-----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2jyNP0aVw2Y",
        "outputId": "46e41c04-cdc1-4477-915e-42af9919b6fd"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import StringType,BooleanType,DateType\n",
        "df2 = df.withColumn(\"age\",col(\"age\").cast(StringType())).withColumn(\"isGraduated\",col(\"isGraduated\").cast(BooleanType())).withColumn(\"jobStartDate\",col(\"jobStartDate\").cast(DateType()))\n",
        "df2.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- jobStartDate: date (nullable = true)\n",
            " |-- isGraduated: boolean (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_iBHOMyWPfA",
        "outputId": "30a2932a-5fb3-4f4d-984f-76e948f38327"
      },
      "source": [
        "df3 = df2.selectExpr(\"cast(age as int) age\",\"cast(isGraduated as string) isGraduated\",\"cast(jobStartDate as string) jobStartDate\")\n",
        "df3.printSchema()\n",
        "df3.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- isGraduated: string (nullable = true)\n",
            " |-- jobStartDate: string (nullable = true)\n",
            "\n",
            "+---+-----------+------------+\n",
            "|age|isGraduated|jobStartDate|\n",
            "+---+-----------+------------+\n",
            "|34 |true       |2006-01-01  |\n",
            "|33 |true       |1980-01-10  |\n",
            "|37 |false      |null        |\n",
            "+---+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqoRT3roXLS4",
        "outputId": "03b03c8f-a982-44c2-d0bb-2d4dfab3e8fb"
      },
      "source": [
        "df3.createOrReplaceTempView(\"Cast\")\n",
        "df4 = spark.sql(\"SELECT STRING(age),BOOLEAN(isGraduated),DATE(jobStartDate) from Cast\")\n",
        "df4.printSchema()\n",
        "df4.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: string (nullable = true)\n",
            " |-- isGraduated: boolean (nullable = true)\n",
            " |-- jobStartDate: date (nullable = true)\n",
            "\n",
            "+---+-----------+------------+\n",
            "|age|isGraduated|jobStartDate|\n",
            "+---+-----------+------------+\n",
            "|34 |true       |2006-01-01  |\n",
            "|33 |true       |1980-01-10  |\n",
            "|37 |false      |null        |\n",
            "+---+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGDLm6RIYBdZ",
        "outputId": "5f087ce0-23df-482f-df8f-fcdcfd8a239a"
      },
      "source": [
        "from pyspark.sql.functions import col,round,expr\n",
        "df.withColumn(\"salary\",df.salary.cast('float')).printSchema()    \n",
        "df.withColumn(\"salary\",col(\"salary\").cast('double')).printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            " |-- jobStartDate: string (nullable = true)\n",
            " |-- isGraduated: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: float (nullable = true)\n",
            "\n",
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            " |-- jobStartDate: string (nullable = true)\n",
            " |-- isGraduated: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qdsnq0xDYoHh",
        "outputId": "24e56beb-1424-4b7b-c7a5-755eca640f26"
      },
      "source": [
        "df.selectExpr(\"firstname\",\"isGraduated\",\"cast(salary as double) salary\").printSchema()    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- isGraduated: string (nullable = true)\n",
            " |-- salary: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjOHZWb2ZGyL",
        "outputId": "d2927e12-eb8d-4031-a170-fc60413a712f"
      },
      "source": [
        "df.createOrReplaceTempView(\"cast\")\n",
        "spark.sql(\"SELECT firstname,isGraduated,DOUBLE(salary) as salary from cast\").printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- isGraduated: string (nullable = true)\n",
            " |-- salary: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxHgMzsIbDB8",
        "outputId": "b5e6cd8c-5314-4b21-b3a0-d8b0a91e479d"
      },
      "source": [
        "dept = [(\"Finance\",10),(\"Marketing\",20),(\"Sales\",30),(\"IT\",40)]\n",
        "deptColumns = [\"dept_name\",\"dept_id\"]\n",
        "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
        "deptDF.show(truncate=False)\n",
        "\n",
        "data = deptDF.collect()\n",
        "print(data)\n",
        "print()\n",
        "dataCollect2 = deptDF.select(\"dept_name\").collect()\n",
        "print(dataCollect2)\n",
        "print()\n",
        "for row in data:\n",
        "    print(row['dept_name'] + \",\" +str(row['dept_id']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|Finance  |10     |\n",
            "|Marketing|20     |\n",
            "|Sales    |30     |\n",
            "|IT       |40     |\n",
            "+---------+-------+\n",
            "\n",
            "[Row(dept_name='Finance', dept_id=10), Row(dept_name='Marketing', dept_id=20), Row(dept_name='Sales', dept_id=30), Row(dept_name='IT', dept_id=40)]\n",
            "\n",
            "[Row(dept_name='Finance'), Row(dept_name='Marketing'), Row(dept_name='Sales'), Row(dept_name='IT')]\n",
            "\n",
            "Finance,10\n",
            "Marketing,20\n",
            "Sales,30\n",
            "IT,40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xinBaJecKgc",
        "outputId": "29a07c88-b126-488a-a632-791c78e871a7"
      },
      "source": [
        "print('PySpark Coloumn Functions')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PySpark Coloumn Functions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5WQpLKec41R",
        "outputId": "276e7d90-da06-4064-ab36-662f2cac1f4d"
      },
      "source": [
        "data=[(\"varun\",\"nagendra\",\"100\",'M'),(\"sravani\",\"yakkanti\",\"200\",'F'),(\"sri\",\"vidya\",\"400\",'F'),(\"ishwarya\",\"himabindu\",\"400\",'F')] \n",
        "columns=[\"fname\",\"lname\",\"id\",\"gender\"]\n",
        "df=spark.createDataFrame(data,columns)\n",
        "print(df.show(truncate=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+---+------+\n",
            "|fname   |lname    |id |gender|\n",
            "+--------+---------+---+------+\n",
            "|varun   |nagendra |100|M     |\n",
            "|sravani |yakkanti |200|F     |\n",
            "|sri     |vidya    |400|F     |\n",
            "|ishwarya|himabindu|400|F     |\n",
            "+--------+---------+---+------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAzQfZnsfyMh",
        "outputId": "254c8c64-38ee-423b-f693-16579ab80c6a"
      },
      "source": [
        "#alias\n",
        "from pyspark.sql.functions import expr\n",
        "df.select(df.fname.alias(\"first_name\"),df.lname.alias(\"last_name\"),expr(\" fname ||','|| lname\").alias(\"fullName\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+------------------+\n",
            "|first_name|last_name|          fullName|\n",
            "+----------+---------+------------------+\n",
            "|     varun| nagendra|    varun,nagendra|\n",
            "|   sravani| yakkanti|  sravani,yakkanti|\n",
            "|       sri|    vidya|         sri,vidya|\n",
            "|  ishwarya|himabindu|ishwarya,himabindu|\n",
            "+----------+---------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VdV_sj3hvZ-",
        "outputId": "39cd2b63-838b-4af6-8b03-d2913a4d7d55"
      },
      "source": [
        "#asc, desc\n",
        "df.sort(df.id.asc()).show()\n",
        "df.sort(df.id.desc()).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+---+------+\n",
            "|   fname|    lname| id|gender|\n",
            "+--------+---------+---+------+\n",
            "|   varun| nagendra|100|     M|\n",
            "| sravani| yakkanti|200|     F|\n",
            "|     sri|    vidya|400|     F|\n",
            "|ishwarya|himabindu|400|     F|\n",
            "+--------+---------+---+------+\n",
            "\n",
            "+--------+---------+---+------+\n",
            "|   fname|    lname| id|gender|\n",
            "+--------+---------+---+------+\n",
            "|     sri|    vidya|400|     F|\n",
            "|ishwarya|himabindu|400|     F|\n",
            "| sravani| yakkanti|200|     F|\n",
            "|   varun| nagendra|100|     M|\n",
            "+--------+---------+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv4_4-jCiNQv",
        "outputId": "1c4e03db-6e89-4f44-8593-3f31d7d5e793"
      },
      "source": [
        "#cast\n",
        "df.select(df.fname,df.id.cast(\"int\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+\n",
            "|   fname| id|\n",
            "+--------+---+\n",
            "|   varun|100|\n",
            "| sravani|200|\n",
            "|     sri|400|\n",
            "|ishwarya|400|\n",
            "+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3wee4uukDys",
        "outputId": "55a955bd-268b-4f9e-c74f-2d22b97e4b87"
      },
      "source": [
        "#between\n",
        "df.filter(df.id.between(100,300)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+---+------+\n",
            "|  fname|   lname| id|gender|\n",
            "+-------+--------+---+------+\n",
            "|  varun|nagendra|100|     M|\n",
            "|sravani|yakkanti|200|     F|\n",
            "+-------+--------+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyXqib8KkiNQ",
        "outputId": "51fbed87-1224-4f34-cfce-60b9c406e5b4"
      },
      "source": [
        "#contains\n",
        "df.filter(df.fname.contains(\"varun\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------+---+------+\n",
            "|fname|   lname| id|gender|\n",
            "+-----+--------+---+------+\n",
            "|varun|nagendra|100|     M|\n",
            "+-----+--------+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzPZ09cZkwG4",
        "outputId": "84ec2211-6a80-4af4-cdfb-8dc8f9cb07ad"
      },
      "source": [
        "#startswith, endswith()\n",
        "df.filter(df.fname.startswith(\"v\")).show()\n",
        "df.filter(df.fname.endswith(\"i\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------+---+------+\n",
            "|fname|   lname| id|gender|\n",
            "+-----+--------+---+------+\n",
            "|varun|nagendra|100|     M|\n",
            "+-----+--------+---+------+\n",
            "\n",
            "+-------+--------+---+------+\n",
            "|  fname|   lname| id|gender|\n",
            "+-------+--------+---+------+\n",
            "|sravani|yakkanti|200|     F|\n",
            "|    sri|   vidya|400|     F|\n",
            "+-------+--------+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG0R1fFvk0LD",
        "outputId": "6eaa114a-55b5-4d99-91e6-a0ba640e3610"
      },
      "source": [
        "#eqNullSafe\n",
        "#isNull & isNotNull\n",
        "df.filter(df.lname.isNull()).show()\n",
        "df.filter(df.lname.isNotNull()).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+---+------+\n",
            "|fname|lname| id|gender|\n",
            "+-----+-----+---+------+\n",
            "+-----+-----+---+------+\n",
            "\n",
            "+--------+---------+---+------+\n",
            "|   fname|    lname| id|gender|\n",
            "+--------+---------+---+------+\n",
            "|   varun| nagendra|100|     M|\n",
            "| sravani| yakkanti|200|     F|\n",
            "|     sri|    vidya|400|     F|\n",
            "|ishwarya|himabindu|400|     F|\n",
            "+--------+---------+---+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI6B7EAklAzQ",
        "outputId": "3592266b-d4cd-4112-e1b6-30362163b434"
      },
      "source": [
        "#like , rlike\n",
        "df.select(df.fname,df.lname,df.id).filter(df.fname.like(\"%varun\")).show() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------+---+\n",
            "|fname|   lname| id|\n",
            "+-----+--------+---+\n",
            "|varun|nagendra|100|\n",
            "+-----+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNrK6Jn-lKP4",
        "outputId": "35d673ab-e53f-4537-dd4c-17659a672d2a"
      },
      "source": [
        "#over ,#substr\n",
        "df.select(df.fname.substr(1,4).alias(\"substr\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|substr|\n",
            "+------+\n",
            "|  varu|\n",
            "|  srav|\n",
            "|   sri|\n",
            "|  ishw|\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6graCRmSlgOO",
        "outputId": "d837fd3a-789c-4ed1-e2aa-04b65dd44785"
      },
      "source": [
        "#when & otherwise\n",
        "from pyspark.sql.functions import when\n",
        "df.select(df.fname,df.lname,when(df.gender==\"M\",\"Male\").when(df.gender==\"F\",\"Female\") .when(df.gender==None ,\"\").otherwise(df.gender).alias(\"new_gender\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+----------+\n",
            "|   fname|    lname|new_gender|\n",
            "+--------+---------+----------+\n",
            "|   varun| nagendra|      Male|\n",
            "| sravani| yakkanti|    Female|\n",
            "|     sri|    vidya|    Female|\n",
            "|ishwarya|himabindu|    Female|\n",
            "+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU2SZD4ImB96",
        "outputId": "8be018b2-090a-4bac-ec78-e49f4e81d282"
      },
      "source": [
        "#isin\n",
        "li=[\"100\",\"200\"]\n",
        "df.select(df.fname,df.lname,df.id).filter(df.id.isin(li)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+---+\n",
            "|  fname|   lname| id|\n",
            "+-------+--------+---+\n",
            "|  varun|nagendra|100|\n",
            "|sravani|yakkanti|200|\n",
            "+-------+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUfpWRpCmQ24"
      },
      "source": [
        "from pyspark.sql.types import StructType,StructField,StringType,ArrayType,MapType\n",
        "data=[((\"James\",\"Bond\"),[\"Java\",\"C#\"],{'hair':'black','eye':'brown'}),((\"Ann\",\"Varsa\"),[\".NET\",\"Python\"],{'hair':'brown','eye':'black'}),((\"Tom Cruise\",\"\"),[\"Python\",\"Scala\"],{'hair':'red','eye':'grey'}),((\"Tom Brand\",None),[\"Perl\",\"Ruby\"],{'hair':'black','eye':'blue'})]\n",
        "schema = StructType([StructField('name', StructType([StructField('fname', StringType(), True),StructField('lname', StringType(), True)])),StructField('languages', ArrayType(StringType()),True),StructField('properties', MapType(StringType(),StringType()),True)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhmJylvUmfsL",
        "outputId": "07a362e3-a83d-4e94-fb3e-69c9b3b53485"
      },
      "source": [
        "df=spark.createDataFrame(data,schema)\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- fname: string (nullable = true)\n",
            " |    |-- lname: string (nullable = true)\n",
            " |-- languages: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- properties: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n",
            "+-----------------+---------------+--------------------+\n",
            "|             name|      languages|          properties|\n",
            "+-----------------+---------------+--------------------+\n",
            "|    {James, Bond}|     [Java, C#]|{eye -> brown, ha...|\n",
            "|     {Ann, Varsa}| [.NET, Python]|{eye -> black, ha...|\n",
            "|   {Tom Cruise, }|[Python, Scala]|{eye -> grey, hai...|\n",
            "|{Tom Brand, null}|   [Perl, Ruby]|{eye -> blue, hai...|\n",
            "+-----------------+---------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhvk_MLfmg4W",
        "outputId": "1eab00c1-4dfb-44a2-eb48-c2373081eb93"
      },
      "source": [
        "#getItem()\n",
        "df.select(df.languages.getItem(0)).show()\n",
        "df.select(df.properties.getItem(\"hair\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|languages[0]|\n",
            "+------------+\n",
            "|        Java|\n",
            "|        .NET|\n",
            "|      Python|\n",
            "|        Perl|\n",
            "+------------+\n",
            "\n",
            "+----------------+\n",
            "|properties[hair]|\n",
            "+----------------+\n",
            "|           black|\n",
            "|           brown|\n",
            "|             red|\n",
            "|           black|\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FppF7zznREE",
        "outputId": "e8f07de1-a5ef-4dd2-d236-65dd1707cd89"
      },
      "source": [
        "#getField from Struct or Map\n",
        "df.select(df.properties.getField(\"hair\")).show()\n",
        "df.select(df.name.getField(\"fname\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|properties[hair]|\n",
            "+----------------+\n",
            "|           black|\n",
            "|           brown|\n",
            "|             red|\n",
            "|           black|\n",
            "+----------------+\n",
            "\n",
            "+----------+\n",
            "|name.fname|\n",
            "+----------+\n",
            "|     James|\n",
            "|       Ann|\n",
            "|Tom Cruise|\n",
            "| Tom Brand|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW5zQgBKnZEy",
        "outputId": "93385fee-0901-46e7-b70a-38c1d83a6bff"
      },
      "source": [
        "#withField\n",
        "from pyspark.sql.functions import lit\n",
        "df.withColumn(\"name\",df.name.withField(\"fname\",lit(\"AA\"))).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------------+--------------------+\n",
            "|       name|      languages|          properties|\n",
            "+-----------+---------------+--------------------+\n",
            "| {AA, Bond}|     [Java, C#]|{eye -> brown, ha...|\n",
            "|{AA, Varsa}| [.NET, Python]|{eye -> black, ha...|\n",
            "|     {AA, }|[Python, Scala]|{eye -> grey, hai...|\n",
            "| {AA, null}|   [Perl, Ruby]|{eye -> blue, hai...|\n",
            "+-----------+---------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL1UzkXBnxuM",
        "outputId": "78d6e939-c1cd-437a-a21f-151080fc8b1a"
      },
      "source": [
        "data=[(\"Varun\",24),(\"Nagendra\",23)]\n",
        "df=spark.createDataFrame(data).toDF(\"name\",\"gender\")\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- gender: long (nullable = true)\n",
            "\n",
            "+--------+------+\n",
            "|    name|gender|\n",
            "+--------+------+\n",
            "|   Varun|    24|\n",
            "|Nagendra|    23|\n",
            "+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q990qql6o5TS",
        "outputId": "65a0ea2f-935b-46ee-9793-3b010c9293c6"
      },
      "source": [
        "from pyspark.sql.functions import col\n",
        "print('selecting coloumn from dataframe using col')\n",
        "df.select(col(\"name\")).show()\n",
        "print('selecting coloumn from dataframe')\n",
        "df.select(df[\"name\"]).show()\n",
        "print('adding new_coloumn using withColumn')\n",
        "df.withColumn(\"new_col\",col(\"name\").substr(1,4)).show()\n",
        "print('Applying Filters')\n",
        "df.filter(col(\"name\").startswith(\"V\")).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "selecting coloumn from dataframe using col\n",
            "+--------+\n",
            "|    name|\n",
            "+--------+\n",
            "|   Varun|\n",
            "|Nagendra|\n",
            "+--------+\n",
            "\n",
            "selecting coloumn from dataframe\n",
            "+--------+\n",
            "|    name|\n",
            "+--------+\n",
            "|   Varun|\n",
            "|Nagendra|\n",
            "+--------+\n",
            "\n",
            "adding new_coloumn using withColumn\n",
            "+--------+------+-------+\n",
            "|    name|gender|new_col|\n",
            "+--------+------+-------+\n",
            "|   Varun|    24|   Varu|\n",
            "|Nagendra|    23|   Nage|\n",
            "+--------+------+-------+\n",
            "\n",
            "Applying Filters\n",
            "+-----+------+\n",
            "| name|gender|\n",
            "+-----+------+\n",
            "|Varun|    24|\n",
            "+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc0euCyqqFUh",
        "outputId": "77496b65-62f9-4119-a10e-34bf3b0bffbc"
      },
      "source": [
        "# Using DataFrame object\n",
        "df.select(df.gender).show()\n",
        "df.select(df[\"gender\"]).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|gender|\n",
            "+------+\n",
            "|    24|\n",
            "|    23|\n",
            "+------+\n",
            "\n",
            "+------+\n",
            "|gender|\n",
            "+------+\n",
            "|    24|\n",
            "|    23|\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkeaL96TqtRa",
        "outputId": "fd59ba57-6418-4b81-b65c-ed59df89121a"
      },
      "source": [
        "# Column operators\n",
        "data=[(1,2,3),(4,5,6),(7,8,9)]\n",
        "df=spark.createDataFrame(data).toDF(\"col1\",\"col2\",\"col3\")\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+\n",
            "|col1|col2|col3|\n",
            "+----+----+----+\n",
            "|   1|   2|   3|\n",
            "|   4|   5|   6|\n",
            "|   7|   8|   9|\n",
            "+----+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKE4yd97rEAl",
        "outputId": "69ae36db-76e4-47f4-c5c3-fd8fef4732bf"
      },
      "source": [
        "df.select(df.col1 + df.col2).show()\n",
        "df.select(df.col1 - df.col2).show() \n",
        "df.select(df.col1 * df.col2).show()\n",
        "df.select(df.col1 / df.col2).show()\n",
        "df.select(df.col1 % df.col2).show()\n",
        "df.select(df.col2 > df.col3).show()\n",
        "df.select(df.col2 < df.col3).show()\n",
        "df.select(df.col2 == df.col3).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|(col1 + col2)|\n",
            "+-------------+\n",
            "|            3|\n",
            "|            9|\n",
            "|           15|\n",
            "+-------------+\n",
            "\n",
            "+-------------+\n",
            "|(col1 - col2)|\n",
            "+-------------+\n",
            "|           -1|\n",
            "|           -1|\n",
            "|           -1|\n",
            "+-------------+\n",
            "\n",
            "+-------------+\n",
            "|(col1 * col2)|\n",
            "+-------------+\n",
            "|            2|\n",
            "|           20|\n",
            "|           56|\n",
            "+-------------+\n",
            "\n",
            "+-------------+\n",
            "|(col1 / col2)|\n",
            "+-------------+\n",
            "|          0.5|\n",
            "|          0.8|\n",
            "|        0.875|\n",
            "+-------------+\n",
            "\n",
            "+-------------+\n",
            "|(col1 % col2)|\n",
            "+-------------+\n",
            "|            1|\n",
            "|            4|\n",
            "|            7|\n",
            "+-------------+\n",
            "\n",
            "+-------------+\n",
            "|(col2 > col3)|\n",
            "+-------------+\n",
            "|        false|\n",
            "|        false|\n",
            "|        false|\n",
            "+-------------+\n",
            "\n",
            "+-------------+\n",
            "|(col2 < col3)|\n",
            "+-------------+\n",
            "|         true|\n",
            "|         true|\n",
            "|         true|\n",
            "+-------------+\n",
            "\n",
            "+-------------+\n",
            "|(col2 = col3)|\n",
            "+-------------+\n",
            "|        false|\n",
            "|        false|\n",
            "|        false|\n",
            "+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIr2Lbh6vVCE"
      },
      "source": [
        "data=[((\"James\",None,\"Smith\"),\"OH\",\"M\"),((\"Anna\",\"Rose\",\"\"),\"NY\",\"F\"),((\"Julia\",\"\",\"Williams\"),\"OH\",\"F\"),((\"Maria\",\"Anne\",\"Jones\"),\"NY\",\"M\"),((\"Jen\",\"Mary\",\"Brown\"),\"NY\",\"M\"),((\"Mike\",\"Mary\",\"Williams\"),\"OH\",\"M\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtoX1S9dgJMr"
      },
      "source": [
        "from pyspark.sql.types import StructType,StructField, StringType        \n",
        "schema = StructType([StructField('name', StructType([StructField('firstname', StringType(), True),StructField('middlename', StringType(), True),StructField('lastname', StringType(), True)])),StructField('state', StringType(), True),StructField('gender', StringType(), True)])\n",
        "df2 = spark.createDataFrame(data = data, schema = schema)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NExJ0DmGgLS7",
        "outputId": "f9b6e6af-0ffc-40fc-f21e-813dc011b285"
      },
      "source": [
        "df2.printSchema()\n",
        "df2.show(truncate=False) # shows all columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            "\n",
            "+----------------------+-----+------+\n",
            "|name                  |state|gender|\n",
            "+----------------------+-----+------+\n",
            "|{James, null, Smith}  |OH   |M     |\n",
            "|{Anna, Rose, }        |NY   |F     |\n",
            "|{Julia, , Williams}   |OH   |F     |\n",
            "|{Maria, Anne, Jones}  |NY   |M     |\n",
            "|{Jen, Mary, Brown}    |NY   |M     |\n",
            "|{Mike, Mary, Williams}|OH   |M     |\n",
            "+----------------------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhbNbJJwhPJy",
        "outputId": "47ff70bc-7f77-42a9-8013-9d6759de3d1e"
      },
      "source": [
        "df2.select(\"name.firstname\",\"name.lastname\").show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+\n",
            "|firstname|lastname|\n",
            "+---------+--------+\n",
            "|James    |Smith   |\n",
            "|Anna     |        |\n",
            "|Julia    |Williams|\n",
            "|Maria    |Jones   |\n",
            "|Jen      |Brown   |\n",
            "|Mike     |Williams|\n",
            "+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EG2jeNUh8Ht",
        "outputId": "a847e700-cb35-4320-b12a-e39eda3eaf0a"
      },
      "source": [
        "df2.select(\"name.*\").show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+\n",
            "|firstname|middlename|lastname|\n",
            "+---------+----------+--------+\n",
            "|James    |null      |Smith   |\n",
            "|Anna     |Rose      |        |\n",
            "|Julia    |          |Williams|\n",
            "|Maria    |Anne      |Jones   |\n",
            "|Jen      |Mary      |Brown   |\n",
            "|Mike     |Mary      |Williams|\n",
            "+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5GyvpBfiUSy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}